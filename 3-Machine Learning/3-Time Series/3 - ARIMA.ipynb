{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR & MA Models\n",
    "In time series, autoregression(AR) and moving average (MA) models provide a simple description of a process in terms of two factors--one for autoregression and the other for moving average. The AR part entails regressing the variable on its own lagged values. The idea is that the previous time period's value can help us predict the current time period's value. The MA part involves modeling the error term as a linear combination of error terms occurring at the same time step and at various times in the past.\n",
    "\n",
    "### Autoregressive Models\n",
    "Autoregressive (AR) Model is when present value of a time series can be predicted from using previous values of the same series. It's a regression using its same series, though shifted by a time step, called a lag. The present value is a weighted average of its past values. Both the t-1 and t-2 are lags of the time series y. The error term (noise) is represented as e. The values a1 and a2 are the coefficients of the model.\n",
    "\n",
    "AR(1) model: $y_{t}$ = $a_{1}$$y_{t-1}$ + $e_{t}$\n",
    "\n",
    "AR(2) model: $y_{t}$ = $a_{1}$$y_{t-1}$ + $a_{2}$$y_{t-2}$ + $e_{t}$\n",
    "\n",
    "We typically represent the order of the model as p for an AR model such as AR(p).\n",
    "\n",
    "### Moving Average Models\n",
    "Moving average (MA) is a process where the present value of a time series, y, is defined as a linear combination of past errors. The error term (noise) is represented as e. Both the t-1 and t-2 are lags of the time on the errors.\n",
    "\n",
    "MA(1) model: $y_{t}$ = $m_{1}$$e_{t-1}$ + $e_{t}$\n",
    "\n",
    "MA(2) model: $y_{t}$ = $m_{1}$$e_{t-1}$ + $m_{2}$$e_{t-2}$ + $e_{t}$\n",
    "\n",
    "We typically represent the order of the model as q for a MA model such as MA(q).\n",
    "\n",
    "### ARMA Models\n",
    "We can combine both Autoregressive and Moving Average models together to create an ARMA model. The time series is regressed on the previous values and the previous errors.\n",
    "\n",
    "ARMA(1,1) model: $y_{t}$ = $a_{1}$$y_{t-1}$ + $m_{1}$$e_{t-1}$\n",
    "\n",
    "For ARMA(p, q), p is the order of the AR process and q is the order of the MA process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast quality metrics\n",
    "\n",
    "Before we begin forecasting, let's understand how to measure the quality of our predictions and take a look at the most commonly used metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [R squared](http://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination): coefficient of determination (in econometrics, this can be interpreted as the percentage of variance explained by the model), $(-\\infty, 1]$\n",
    "\n",
    "$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$ \n",
    "\n",
    "```python\n",
    "sklearn.metrics.r2_score\n",
    "```\n",
    "---\n",
    "- [Mean Absolute Error](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error): this is an interpretable metric because it has the same unit of measurment as the initial series, $[0, +\\infty)$\n",
    "\n",
    "$MAE = \\frac{\\sum\\limits_{i=1}^{n} |y_i - \\hat{y}_i|}{n}$ \n",
    "\n",
    "```python\n",
    "sklearn.metrics.mean_absolute_error\n",
    "```\n",
    "---\n",
    "- [Median Absolute Error](http://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error): again, an interpretable metric that is particularly interesting because it is robust to outliers, $[0, +\\infty)$\n",
    "\n",
    "$MedAE = median(|y_1 - \\hat{y}_1|, ... , |y_n - \\hat{y}_n|)$\n",
    "\n",
    "```python\n",
    "sklearn.metrics.median_absolute_error\n",
    "```\n",
    "---\n",
    "- [Mean Squared Error](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error): the most commonly used metric that gives a higher penalty to large errors and vice versa, $[0, +\\infty)$\n",
    "\n",
    "$MSE = \\frac{1}{n}\\sum\\limits_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "```python\n",
    "sklearn.metrics.mean_squared_error\n",
    "```\n",
    "---\n",
    "- [Mean Squared Logarithmic Error](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-logarithmic-error): practically, this is the same as MSE, but we take the logarithm of the series. As a result, we give more weight to small mistakes as well. This is usually used when the data has exponential trends, $[0, +\\infty)$\n",
    "\n",
    "$MSLE = \\frac{1}{n}\\sum\\limits_{i=1}^{n} (log(1+y_i) - log(1+\\hat{y}_i))^2$\n",
    "\n",
    "```python\n",
    "sklearn.metrics.mean_squared_log_error\n",
    "```\n",
    "---\n",
    "- Mean Absolute Percentage Error: this is the same as MAE but is computed as a percentage, which is very convenient when you want to explain the quality of the model to management, $[0, +\\infty)$\n",
    "\n",
    "$MAPE = \\frac{100}{n}\\sum\\limits_{i=1}^{n} \\frac{|y_i - \\hat{y}_i|}{y_i}$ \n",
    "\n",
    "```python\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analítica\n",
    "Vamos a utilizar los datos de ventas de Johnson&Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "from pmdarima.arima import ARIMA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/jj.csv', index_col=0)\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data'].plot(figsize=(15,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aprecia en la gráfica que presenta diferentes estadísticos a lo largo del tiempo.\n",
    "\n",
    "Representamos sus gráficas de autocorrelación. Vemos que tenemos muy complicado determinar el orden p y q, de cara al modelo ARIMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(data['data']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive\n",
    "Tendremos que encontrar el orden de autoregression que mejor encaje con nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test)\n",
    "plt.plot(predictions,color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parece que de buen resultado el AR(1,0,0). Probemos diferentes lags, a ver cuál sería el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = []\n",
    "mse = []\n",
    "for lag in range(1, 15):\n",
    "    try:\n",
    "        ##### CODE #####\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "plt.plot(lags, mse);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un parámetro p=1, p=2 o p=5 parece que da buen resultado, pero aun asi es muy alto el error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average\n",
    "En este caso tendremos en cuenta los errores. El problema es que si tenemos muchos errores al principio, los iremos arrastrando durante las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_ar_fit.predict(14)\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test)\n",
    "plt.plot(predictions,color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No está dando buen resultado. Probaremos entonces varios lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = []\n",
    "mse = []\n",
    "for lag in range(1, 20):\n",
    "    try:\n",
    "        model_ar = ARIMA(order=(0, 0, lag))\n",
    "        model_ar_fit = model_ar.fit(train)\n",
    "        predictions = model_ar_fit.predict(14)\n",
    "        lags.append(lag)\n",
    "        mse.append(mean_squared_error(test, predictions))\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "plt.plot(lags, mse);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que según vamos aumentando el parámetro `q` del modelo Moving Average, va disminuyendo el error, pero aun así es bastante grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "En el arima no solo influyen los parámetros `p` y `q`, sino que también tendremos en cuenta `d`. Parametro con el que diferenciaremos la serie y conseguiremos que sea estacionaria.\n",
    "\n",
    "Ahora bien, ¿cuál es la mejor combinación de parámetros? Tendremos que realizar varias pruebas. Para comparar los modelos se suele utilizar el AIC.\n",
    "\n",
    "### AIC\n",
    "Akaike’s Information Criterion\n",
    "\n",
    "![imagen](./img/aic.png)\n",
    "\n",
    "k es el número de parámetros del modelo estadístico y L es el máximo valor de la función de verosimilitud para el modelo estimado. La función de verosimilitud permite realizar inferencias a partir de u conjunto de observaciones.\n",
    "\n",
    "Se utiliza para seleccionar el mejor modelo, que será el que tiene menor AIC. El AIC depende mucho de cada dato, y es una medida de comparación entre modelos, no de presentación de resultados. Un AIC bajo no quiere decir que el modelo sea muy bueno. Por tanto, AIC no nos dice nada sobre la calidad del modelo en terminos absolutos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cómo conseguir los mejores p, d, q?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for param in pdq:\n",
    "    try:\n",
    "        model_arima = ARIMA(order=param)\n",
    "        model_arima_fit = model_arima.fit(train)\n",
    "        results.append((param,model_arima_fit.aic()))\n",
    "    except:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_df = pd.DataFrame(results, columns=['ARIMA params', 'AIC']).sort_values('AIC')\n",
    "resultados_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos la mejor combinación de parámetros para el ARIMA. Probemos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(14)\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "model.fit(train)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMAX\n",
    "La X viene de exogenous. Significa que le podemos añadir una variable externa con la que entrenar el modelo.\n",
    "\n",
    "Vamos a probar con los datos de la bolsa. Primero un auto_arima con los datos a cierre. Y después un auto_arima acompañado de los datos de apertura de bolsa, a ver cuánto ayudan a predecir el cierre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = pd.read_csv('data/FB.csv', header=0, index_col=0)\n",
    "print(len(stock_df))\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df['Close'].plot(figsize=(15,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos primero ejemplo sin variable exogena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = stock_df['Close'][0:1240].values\n",
    "test = stock_df['Close'][1240:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar varios ARIMAS, a ver cuál sería la mejor combinación de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_model = auto_arima(train,\n",
    "                            start_p=1,\n",
    "                            start_q=1,\n",
    "                            max_d=3,\n",
    "                            max_p=5,\n",
    "                            max_q=5,\n",
    "                            stationary=False,\n",
    "                            trace=True,\n",
    "                           stepwise=True)\n",
    "print(stepwise_model.aic())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya lo tenemos, ahora montaremos el modelo con esos hiperparámetros y vemos que AIC tiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(order=(1,1,1))\n",
    "model.fit(train)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(19)\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a compararlo con el mismo modelo, pero en este caso le añadimos una variable exogena al entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce bastante el AIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos a entrenar el auto arima con la variable exogena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "\n",
    "print(model.aic())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos varias variables exogenas\n",
    "\n",
    "NOTA: para este apartado se utiliza el valor 'Low', que en la vida real no lo tendriamos para realizar la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "\n",
    "print(model.aic())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA\n",
    "Veamos cómo podemos predecir con datos que tienen estacionalidad, es decir, que cuentan con un patrón que se repite a lo largo del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/a10.csv', parse_dates=['date'], index_col='date')\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'].plot(figsize=(15,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result_add = seasonal_decompose(df[['value' ]], model='additive', extrapolate_trend='freq')\n",
    "\n",
    "# Plot\n",
    "plt.rcParams.update({'figure.figsize': (6,6)})\n",
    "result_add.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos el auto arima sin indicarle que hay componente de seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_arima(train,\n",
    "                    start_p=1,\n",
    "                    start_q=1,\n",
    "                    max_d=3,\n",
    "                    max_p=5,\n",
    "                    max_q=5,\n",
    "                    trace=True,\n",
    "                    stepwise=True)\n",
    "\n",
    "print(model.aic())\n",
    "\n",
    "predictions = model.predict(20)\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora le añadimos el componente seasonality mediante el parametro `m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "\n",
    "print(model.aic())\n",
    "\n",
    "predictions = model.predict(20)\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
