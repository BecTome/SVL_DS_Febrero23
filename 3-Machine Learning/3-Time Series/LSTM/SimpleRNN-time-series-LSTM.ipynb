{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-series prediction with Keras `SimpleRNN` class\n",
    "### Dr. Tirthajyoti Sarkar, Fremont, CA 94536 ([LinkedIn](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/), [Github](https://tirthajyoti.github.io))\n",
    "\n",
    "For more tutorial-style notebooks on deep learning, **[here is my Github repo](https://github.com/tirthajyoti/Deep-learning-with-Python)**.\n",
    "\n",
    "For more tutorial-style notebooks on general machine learning, **[here is my Github repo](https://github.com/tirthajyoti/Machine-Learning-with-Python)**.\n",
    "\n",
    "---\n",
    "### What is this Notebook about?\n",
    "In this notebook, we show a building simple recurrent neural network (RNN) using Keras.\n",
    "\n",
    "We will generate some synthetic time-series data by multiplying two periodic/ sinusoidal signals and adding some stochasticity (Gaussian noise). Then, we will take a small fraction of the data and train a simple RNN model with it and try to predict the rest of the data and see how the predictions match up with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "\n",
    "np.random.seed(0)\n",
    "t=np.arange(0,N)\n",
    "x=(2*np.sin(0.02*t)*np.sin(0.003*t))+0.5*np.random.normal(size=N)\n",
    "df = pd.DataFrame(x, columns=['Data'])\n",
    "\n",
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the values in train and test\n",
    "\n",
    "So, we took only 25% of the data as training samples and set aside the rest of the data for testing. \n",
    "\n",
    "Looking at the time-series plot, we think **it is not easy for a standard model to come up with correct trend predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Train data length:\", train.shape)\n",
    "print(\"Test data length:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step (or _embedding_)\n",
    "RNN model requires a step value that contains n number of elements as an input sequence.\n",
    "\n",
    "Suppose x = {1,2,3,4,5,6,7,8,9,10}\n",
    "\n",
    "for step=1, x input  and its y prediction become:\n",
    "\n",
    "| x  | y  |\n",
    "|---|---|\n",
    "| 1  | 2  |\n",
    "| 2  | 3  |\n",
    "| 3  | 4  |\n",
    "| ...  | ...  |\n",
    "| 9  | 10  |\n",
    "\n",
    "for step=3, x and y contain:\n",
    "\n",
    "| x  | y  |\n",
    "|---|---|\n",
    "| 1,2,3  | 4  |\n",
    "| 2,3,4  | 5  |\n",
    "| 3,4,5  | 6  |\n",
    "| ...  | ...  |\n",
    "| 7,8,9  | 10  |\n",
    "\n",
    "Here, we choose `step=4`. In more complex RNN and in particular for text processing, this is also called _embedding size_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "print(\"Train data length:\", trainX.shape)\n",
    "print(\"Train target length:\", trainY.shape)\n",
    "print(\"Test data length:\", testX.shape)\n",
    "print(\"Test target length:\", testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar el modelo, necesito que los datos tengan la siguiente dimensión:\n",
    "\n",
    "(750, 1, 4)\n",
    "\n",
    "- 750: el número total de trozos \n",
    "- 1: una fila de datos\n",
    "- 4: cada trozo tiene cuatro valores\n",
    "\n",
    "En el caso de una imagen, recordemos con un ejemplo: \n",
    "\n",
    "(750, 28, 28)\n",
    "\n",
    "750 imágenes de resolución 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Training data shape:\", trainX.shape,', ',trainY.shape)\n",
    "print(\"Test data shape:\", testX.shape,', ',testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras model\n",
    "\n",
    "- 256 neurons in the RNN layer\n",
    "- 32 neurons in the densely connected layer\n",
    "- A single neuron for the output layer. Predict a single number\n",
    "- ReLu activation\n",
    "- learning rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "def build_simple_rnn(num_units=128, embedding=4,num_dense=32,lr=0.001):\n",
    "    ##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_simple_rnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple callback class to show a message every 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch+1) % 50 == 0 and epoch>0:\n",
    "            print(\"Epoch number {} done\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con batch_size = 16 lo que haríamos es que cogemos los datos de esta forma:\n",
    "\n",
    "- (16, 1, 4)\n",
    "\n",
    "Cogemos 16 trozos de 1 fila con 4 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"RMSE loss over epochs\",fontsize=16)\n",
    "plt.plot(np.sqrt(model.history.history['loss']),c='k',lw=2)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Epochs\",fontsize=14)\n",
    "plt.ylabel(\"Root-mean-squared error\",fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "Note that the model was fitted only with the `trainX` and `trainY` data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"This is what the model saw\",fontsize=18)\n",
    "plt.plot(trainX[:,0][:,0],c='blue')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.title(\"This is what the model predicted\",fontsize=18)\n",
    "plt.plot(testPredict,c='orange')\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing it with the ground truth (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df2.index.values\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "plt.plot(index,df2,c='blue')\n",
    "plt.plot(index,predicted,c='orange',alpha=0.75)\n",
    "plt.legend(['True data','Predicted'],fontsize=15)\n",
    "plt.axvline(df.index[Tp], c=\"r\")\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the errors distributed?\n",
    "The errors, or residuals, as they are called in a regression problem, can be plotted to see if they follow any specific distribution. In the generation process, we injected Gaussian noise, so we expect the error to follow the same pattern, _if the model has been able to fit to the real data correctly_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "error = np.array(error).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.hist(error,bins=25,edgecolor='k',color='orange');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(error,c='blue',alpha=0.75)\n",
    "plt.hlines(y=0,xmin=-50,xmax=2400,color='k',lw=3)\n",
    "plt.xlim(-50,2350)\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the model better\n",
    "\n",
    "Note, for running these experiments reasonably fast, we will fix the model size to be smaller than the model above. We will use a RNN layer with 32 neurons followed by a densely connected layer of 8 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the embedding/step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(model,trainX,testX):\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    predicted = np.concatenate((trainPredict,testPredict),axis=0)\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(predicted, df2):\n",
    "    index = df2.index.values\n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(index,df2,c='blue')\n",
    "    plt.plot(index,predicted,c='orange',alpha=0.75)\n",
    "    plt.legend(['True data','Predicted'],fontsize=15)\n",
    "    plt.axvline(df2.index[Tp], c=\"r\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(step=4):\n",
    "    df2 = df.copy()\n",
    "    emb_size = step\n",
    "    for i in range(1, emb_size+1):\n",
    "        df2['lag' + str(i)] = df2['Data'].shift(i)\n",
    "\n",
    "    df2.dropna(inplace=True)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    values = df2.values\n",
    "\n",
    "    trainX,trainY = values[0:Tp-emb_size ,1:],values[0:Tp-emb_size ,0],\n",
    "    testX,testY = values[Tp-emb_size:N-emb_size,1:], values[Tp-emb_size:N-emb_size,0]\n",
    "    \n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    return trainX,testX,trainY,testY,df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for s in [2,4,6,8,10,12]:\n",
    "    trainX,testX,trainY,testY,df2 = prepare_data(s)\n",
    "    model = build_simple_rnn(num_units=32,num_dense=8,embedding=s)\n",
    "    batch_size=16\n",
    "    num_epochs = 100\n",
    "    model.fit(trainX,trainY, \n",
    "          epochs=num_epochs, \n",
    "          batch_size=batch_size,\n",
    "          verbose=0)\n",
    "    preds = predictions(model,trainX,testX)\n",
    "    print(\"Embedding size: {}\".format(s))\n",
    "    print(\"MAE:\", errors(testX, testY))\n",
    "    print(\"-\"*100)\n",
    "    plot_compare(preds, df2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Probemos ahora con una ventana grande (8), y unas cuantas epochs mas\n",
    "'''\n",
    "for e in [100,200,300,400,500]:\n",
    "    trainX, testX, trainY, testY, df2 = prepare_data(6)\n",
    "    model = build_simple_rnn(num_units=32,num_dense=8,embedding=6)\n",
    "    batch_size=16\n",
    "    num_epochs = e\n",
    "    model.fit(trainX,trainY, \n",
    "          epochs=e, \n",
    "          batch_size=batch_size,\n",
    "          verbose=0)\n",
    "    preds = predictions(model,trainX,testX)\n",
    "    print(\"Ran for {} epochs\".format(e))\n",
    "    print(\"MAE:\", errors(testX, testY))\n",
    "    print(\"-\"*100)\n",
    "    plot_compare(preds, df2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for b in [4,8,16,32,64]:\n",
    "    trainX,testX,trainY,testY, df2 = prepare_data(6)\n",
    "    model = build_simple_rnn(num_units=32,num_dense=8,embedding=6)\n",
    "    batch_size=b\n",
    "    num_epochs = 250\n",
    "    model.fit(trainX,trainY, \n",
    "          epochs=num_epochs, \n",
    "          batch_size=b,\n",
    "          verbose=0)\n",
    "    preds = predictions(model,trainX,testX)\n",
    "    print(\"Ran with batch size: {}\".format(b))\n",
    "    print(\"MAE:\", errors(testX, testY))\n",
    "    print(\"-\"*100)\n",
    "    plot_compare(preds, df2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Clearly, following trends were observed,\n",
    "\n",
    "- Too small embedding size is not useful but a very long embedding is also not effective. An embedding of 8 looks good for this data.\n",
    "- More epochs are not always better. Probably we are suffering overfitting\n",
    "- A batch size of 32 or 64 looks optimal.\n",
    "\n",
    "Ultimately, an exhaustive hyperparameter tuning is needed for the best overall performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
