{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos datos\n",
    "Dataset de Kaggle: https://www.kaggle.com/c/GiveMeSomeCredit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/cs-training.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos cargamos columnas inutiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos cargamos duplicados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de correlación\n",
    "Vamos a cargarnos algunas columnas que no estén muy relacionadas con el target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(np.round(df.corr(), 2),\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            annot=True,\n",
    "            cmap=sns.diverging_palette(145, 280, s=85, l=25, n=7),\n",
    "            square=True,\n",
    "            linewidths=.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividimos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_reg.coef_)\n",
    "print(log_reg.intercept_)\n",
    "print(log_reg.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = log_reg.intercept_\n",
    "coefs = log_reg.coef_.ravel()\n",
    "\n",
    "features = pd.DataFrame(coefs, X_train.columns, columns=['coefficient']).copy()\n",
    "features['coefficient'] = np.abs(features['coefficient'])\n",
    "\n",
    "features.sort_values('coefficient', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdevs = []\n",
    "for i in X_train.columns:\n",
    "    stdev = df[i].std()\n",
    "    stdevs.append(stdev)\n",
    "\n",
    "features[\"stdev\"] = np.array(stdevs).reshape(-1,1)\n",
    "features[\"importance\"] = features[\"coefficient\"] * features[\"stdev\"]\n",
    "features['importance_standarized'] = features['importance'] / y_train.std()\n",
    "\n",
    "features = features.sort_values('importance_standarized', ascending=True)\n",
    "plt.barh(features.index, features.importance_standarized);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features.radviz import radviz\n",
    "\n",
    "# Specify the target classes\n",
    "classes = [\"Pays\", \"Default\"]\n",
    "\n",
    "# Instantiate the visualizer\n",
    "radviz(X, y.values, classes=classes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(c_matrix_df/np.sum(c_matrix_df), annot=True, \n",
    "            fmt='.2%', cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "\n",
    "classes = [\"Pays\", \"Default\"]\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "visualizer = ClassPredictionError(\n",
    "    LogisticRegression(max_iter = 5000), classes=classes\n",
    ")\n",
    "\n",
    "# Fit the training data to the visualizer\n",
    "visualizer.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "visualizer.score(X_test, y_test)\n",
    "\n",
    "# Draw visualization\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.datasets import load_occupancy\n",
    "\n",
    "# Specify the target classes\n",
    "classes = [\"Pays\", \"Default\"]\n",
    "\n",
    "visualizer = ClassificationReport(LogisticRegression(max_iter = 5000), classes=classes, support=True)\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.show();                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "# Instantiate the visualizer with the classification model\n",
    "model = LogisticRegression(max_iter = 5000)\n",
    "classes = [\"Pays\", \"Default\"]\n",
    "\n",
    "visualizer = ROCAUC(model, classes = classes)\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.show();                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold\n",
    "Lo que realmente hace el `model.predict(X_train)` es obtener una probabilidad de ser 1, y a partir de un 50% se considera como 1. Este umbral del 50% lo podremos ir variando dependiendo de si nos interesa focalizar en los falsos positivos o los falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import DiscriminationThreshold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "model = LogisticRegression(multi_class=\"auto\", solver=\"liblinear\")\n",
    "classes = [\"Default\", \"Pays\"]\n",
    "\n",
    "visualizer = DiscriminationThreshold(model)\n",
    "\n",
    "visualizer.fit(X, y)        # Fit the data to the visualizer\n",
    "visualizer.show();           # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "model = LogisticRegression(max_iter = 5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred=model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "def f(punto_corte=0.5):\n",
    "  y_pred=np.where(pred>punto_corte, 1, 0)\n",
    "  conf_mat=pd.crosstab(y_test,\n",
    "                       y_pred[:,1],\n",
    "                       rownames=['Actual'],\n",
    "                       colnames=['Predicted'])\n",
    "    \n",
    "  sns.heatmap(conf_mat, annot=True, fmt='g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(f, punto_corte=(0, 1, 0.01));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap\n",
    "La librería `shap` también es muy útil para interpretar los modelos. Puedes encontrar información en estos dos artículos\n",
    "\n",
    "https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d\n",
    "\n",
    "https://towardsdatascience.com/shap-how-to-interpret-machine-learning-models-with-python-2323f5af4be9\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
