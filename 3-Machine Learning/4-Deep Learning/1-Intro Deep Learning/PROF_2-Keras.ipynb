{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPor defecto, keras no tira de GPU\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "'''\n",
    "Por defecto, keras no tira de GPU\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (these are NumPy arrays). Aplano a una dimension cada imagen.\n",
    "# Escalamos ya que vamos a usar gradient descent, y le afecta mucho la escala de las features.\n",
    "# Ejecutar esta celda solo una vez. Sino reescalará\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Reserve 10,000 samples for validation. Entraran dentro del modelo para validar. No es validacion cruzada\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "print(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una manera de declarar la red neuronal\n",
    "\n",
    "# Siempre hay que declarar la capa sequential para empezar a declarar la red\n",
    "# Se trata de la API sequential\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Flatten, aplana en un unico vector. Y especificamos el tamaño de la entrada\n",
    "# Es como si hiciese un .reshape(-1, 28*28)\n",
    "# \"kernel_initializer\" o \"bias_initializer\" No lo usamos pero seria para inicializar los pesos de otra manera\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Capas de la red. Dense es la capa de neuronas. Necesitamos numero y activacion\n",
    "model.add(keras.layers.Dense(units = 300, # Numero de neuronas de la capa\n",
    "                             activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(100,\n",
    "                             activation='relu'))\n",
    "\n",
    "# Capa de salida, con tamaño del número de clases\n",
    "# Suele ir aqui un softmax. Para multiclase guay. Si es binaria -> sigmoide\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "]\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000023A811BAD00>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x23a811b2fd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23a811bad00>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23a811af550>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23a811ba670>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[1])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()\n",
    "\n",
    "# 784 features (pixeles de las imagenes) x 300 neuronas\n",
    "# Los pesos están inicializados aleatoriamente\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la configuración del entrenamiento (optimizador, pérdida, métricas):\n",
    "model.compile(\n",
    "    # Stocastic gradient descent. El algoritmo para minimizar la loss function\n",
    "    # El stocastic va haciendo muestreo en cada evaluacion, no usa todo el dataset\n",
    "    # Podemos modificar el learning rate(0.01 por defecto) mediante el parametro lr\n",
    "    optimizer=keras.optimizers.SGD(),  # Optimizer\n",
    "    \n",
    "    \n",
    "    # Loss function to minimize\n",
    "    # sparse_categorical_crossentropy cuando tenemos un label en nuna columna\n",
    "    # Si lo tuviesemos en varias tipo dummy, cogeriamos categorical_crossentropy\n",
    "    # binary_crossentropy si es una neurona, clasi binario\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    \n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(optimizer=\"sgd\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "# La primera hidden layer tiene 784 entradas x 300 salidas\n",
    "# Son los 235500 params = 783x300 + 300 (bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.8976 - sparse_categorical_accuracy: 0.7800 - val_loss: 0.3973 - val_sparse_categorical_accuracy: 0.8984\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3731 - sparse_categorical_accuracy: 0.8966 - val_loss: 0.3068 - val_sparse_categorical_accuracy: 0.9154\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3104 - sparse_categorical_accuracy: 0.9121 - val_loss: 0.2665 - val_sparse_categorical_accuracy: 0.9231\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.2758 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.2423 - val_sparse_categorical_accuracy: 0.9322\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2510 - sparse_categorical_accuracy: 0.9290 - val_loss: 0.2294 - val_sparse_categorical_accuracy: 0.9328\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2304 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.2157 - val_sparse_categorical_accuracy: 0.9389\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.2132 - sparse_categorical_accuracy: 0.9397 - val_loss: 0.1988 - val_sparse_categorical_accuracy: 0.9440\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1986 - sparse_categorical_accuracy: 0.9437 - val_loss: 0.1864 - val_sparse_categorical_accuracy: 0.9486\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1860 - sparse_categorical_accuracy: 0.9463 - val_loss: 0.1765 - val_sparse_categorical_accuracy: 0.9507\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1744 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.1671 - val_sparse_categorical_accuracy: 0.9532\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1645 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.1590 - val_sparse_categorical_accuracy: 0.9549\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1550 - sparse_categorical_accuracy: 0.9558 - val_loss: 0.1529 - val_sparse_categorical_accuracy: 0.9571\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1467 - sparse_categorical_accuracy: 0.9584 - val_loss: 0.1467 - val_sparse_categorical_accuracy: 0.9584\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1393 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1422 - val_sparse_categorical_accuracy: 0.9590\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1325 - sparse_categorical_accuracy: 0.9628 - val_loss: 0.1379 - val_sparse_categorical_accuracy: 0.9614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEn el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\\nSi vemos que ya no baja mas, no serán necesarias tantas epochs.\\nImprimera tantas lineas como epochs hayamos puesto\\n\\nTampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\\nUtil para datasets desbalanceados.\\n\\nEl loss que muestra es el categoricalcrossentropy\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo con un batch_size de 64 imágenes por cada iteración, 10 epochs y especificando cuál es el conjunto de validación.\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64, # numero de muestras empleadas en el entrenamiento de SGD\n",
    "    epochs=15, # 1 por defecto. Insuficiente. Numero de vueltas del backpropagation\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    # En vez de validation data podemos usar el argumento validation_split=0.1\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "'''\n",
    "En el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\n",
    "Si vemos que ya no baja mas, no serán necesarias tantas epochs.\n",
    "Imprimera tantas lineas como epochs hayamos puesto\n",
    "\n",
    "Tampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\n",
    "Util para datasets desbalanceados.\n",
    "\n",
    "El loss que muestra es el categoricalcrossentropy\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1264 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.1350 - val_sparse_categorical_accuracy: 0.9628\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1202 - sparse_categorical_accuracy: 0.9665 - val_loss: 0.1304 - val_sparse_categorical_accuracy: 0.9641\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1148 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.1274 - val_sparse_categorical_accuracy: 0.9638\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9654\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1051 - sparse_categorical_accuracy: 0.9706 - val_loss: 0.1198 - val_sparse_categorical_accuracy: 0.9656\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9721 - val_loss: 0.1177 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9674\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1119 - val_sparse_categorical_accuracy: 0.9680\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0889 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9677\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1087 - val_sparse_categorical_accuracy: 0.9693\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1059 - val_sparse_categorical_accuracy: 0.9698\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.1049 - val_sparse_categorical_accuracy: 0.9701\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0762 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9707\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9716\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1008 - val_sparse_categorical_accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de29fb2640>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 15, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.8976293206214905,\n",
       "  0.3731369078159332,\n",
       "  0.31035423278808594,\n",
       "  0.27584534883499146,\n",
       "  0.25101009011268616,\n",
       "  0.23038747906684875,\n",
       "  0.21318088471889496,\n",
       "  0.1985526829957962,\n",
       "  0.18604834377765656,\n",
       "  0.17442892491817474,\n",
       "  0.16447074711322784,\n",
       "  0.15498726069927216,\n",
       "  0.14665693044662476,\n",
       "  0.13933177292346954,\n",
       "  0.13254621624946594],\n",
       " 'sparse_categorical_accuracy': [0.7800400257110596,\n",
       "  0.8966400027275085,\n",
       "  0.9121000170707703,\n",
       "  0.9218999743461609,\n",
       "  0.9290199875831604,\n",
       "  0.9354199767112732,\n",
       "  0.939740002155304,\n",
       "  0.9436799883842468,\n",
       "  0.9463199973106384,\n",
       "  0.9503600001335144,\n",
       "  0.9531199932098389,\n",
       "  0.955780029296875,\n",
       "  0.9584199786186218,\n",
       "  0.9607200026512146,\n",
       "  0.9628000259399414],\n",
       " 'val_loss': [0.3972669839859009,\n",
       "  0.30683276057243347,\n",
       "  0.26653149724006653,\n",
       "  0.24225503206253052,\n",
       "  0.22936606407165527,\n",
       "  0.21573476493358612,\n",
       "  0.19875092804431915,\n",
       "  0.18636974692344666,\n",
       "  0.1764586716890335,\n",
       "  0.16707126796245575,\n",
       "  0.15897685289382935,\n",
       "  0.1529289036989212,\n",
       "  0.14666879177093506,\n",
       "  0.14219506084918976,\n",
       "  0.1379450261592865],\n",
       " 'val_sparse_categorical_accuracy': [0.8984000086784363,\n",
       "  0.9154000282287598,\n",
       "  0.9230999946594238,\n",
       "  0.932200014591217,\n",
       "  0.9327999949455261,\n",
       "  0.9388999938964844,\n",
       "  0.9440000057220459,\n",
       "  0.9485999941825867,\n",
       "  0.9506999850273132,\n",
       "  0.9531999826431274,\n",
       "  0.9549000263214111,\n",
       "  0.957099974155426,\n",
       "  0.9584000110626221,\n",
       "  0.9589999914169312,\n",
       "  0.9613999724388123]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Podemos ver como evoluciona el entrenamiento, en funcion de los epochs\n",
    "# Validacion y training estan muy cerca, no hay overfitting!\n",
    "# Todavia no ha acabado de coverger ya que el loss en validacion sigue bajando,\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9699\n",
      "test loss, test acc: [0.09595837444067001, 0.9699000120162964]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el \"score\" a partir del conjunto de test\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "\n",
    "# Metodo evaluate para que nos de el error vs las metricas elegidas en la funcion compile\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.001, 0.001, 0.   , 0.   , 0.   , 0.998, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ojo aqui viene slicing xq presupone que le entran varios inputs\n",
    "Nos da las probabilidades de pertenecer a una clase u otra.\n",
    "'''\n",
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 973us/step - loss: 1.0690 - val_loss: 0.5387\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.5454 - val_loss: 0.4826\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.5084 - val_loss: 0.4644\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.4627 - val_loss: 0.4409\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.4611 - val_loss: 0.4356\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.4628 - val_loss: 0.4323\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.4393 - val_loss: 0.4233\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.4332 - val_loss: 0.4157\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4146\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.4081\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4033\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.4148 - val_loss: 0.4010\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.4177 - val_loss: 0.3999\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.4069 - val_loss: 0.3912\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 784us/step - loss: 0.4013 - val_loss: 0.3925\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3996 - val_loss: 0.3865\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.3950 - val_loss: 0.3824\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.4034 - val_loss: 0.3867\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.4151 - val_loss: 0.4188\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.4003 - val_loss: 0.3915\n",
      "162/162 [==============================] - 0s 585us/step - loss: 0.3956\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    # No hace falta capa de flatten. No hay que aplanar ninguna imagen\n",
    "    keras.layers.Dense(30, activation=\"relu\",\n",
    "                       input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # una unica neurona de salida\n",
    "    # Sin fun de activa. ReLu no iria mal si el output es positivo. Sigmoide si esta acotado.\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3094\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 779us/step - loss: 0.3074\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3076\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3089\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3057\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3059\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3051\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3048\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.3067\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3037\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3335\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.3203\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3221\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3169\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3200\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.3153\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3141\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.3038 - val_loss: 0.3389\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3169\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3433\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.3198\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3103 - val_loss: 0.3228\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.3201\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.3202\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3065 - val_loss: 0.3236\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 894us/step - loss: 0.3046 - val_loss: 0.3197\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.3230\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3051 - val_loss: 0.3193\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3038 - val_loss: 0.3147\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3031 - val_loss: 0.3164\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3205\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3173\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3162\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.3055 - val_loss: 0.3269\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.3199\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 886us/step - loss: 0.3059 - val_loss: 0.3199\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.3065 - val_loss: 0.3309\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 775us/step - loss: 0.3048 - val_loss: 0.3232\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "10 esta bien. Lo pondemos a 5 para el ejercicio\n",
    "¿Qué considera como dejar de mejorar? parametros min_delta y baseline\n",
    "'''\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, \n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard\n",
    "Keras tiene implementado un dashboard para monitorizar las ejecuciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crea este directorio\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Guarda una carpeta nueva con la fecha de la ejecucion\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/363 [..............................] - ETA: 0s - loss: 0.1658WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0202s). Check your callbacks.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3417\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3287 - val_loss: 0.3366\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.3332\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3278 - val_loss: 0.3341\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3239 - val_loss: 0.3361\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3277 - val_loss: 0.3330\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3233 - val_loss: 0.3274\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.3234 - val_loss: 0.3270\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3201 - val_loss: 0.3265\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3207 - val_loss: 0.3271\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 0s 880us/step - loss: 0.3207 - val_loss: 0.3295\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3382\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3333\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3256 - val_loss: 0.3392\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3226 - val_loss: 0.3339\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.3236 - val_loss: 0.3310\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 0s 899us/step - loss: 0.3252 - val_loss: 0.3512\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3208 - val_loss: 0.3354\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3247\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3236\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3173 - val_loss: 0.3908\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3408\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.3272\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3352\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3404\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.3181 - val_loss: 0.3265\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3146 - val_loss: 0.3216\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3157 - val_loss: 0.3221\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 0s 894us/step - loss: 0.3127 - val_loss: 0.3262\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3126 - val_loss: 0.3308\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3135 - val_loss: 0.3254\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.3117 - val_loss: 0.3239\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3117 - val_loss: 0.3292\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.3272\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3112 - val_loss: 0.3182\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3095 - val_loss: 0.3241\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3183\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3142 - val_loss: 0.3277\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3221\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3232\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.3242\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3287\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.3093 - val_loss: 0.3203\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3186\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.3184 - val_loss: 0.3261\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3231\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.3238\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3092 - val_loss: 0.3193\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3211\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.3207\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fc21116b3e4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensorboard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tensorboard'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--logdir=./my_logs --port=6006'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2324\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2325\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2326\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2327\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\notebook.py\u001b[0m in \u001b[0;36m_start_magic\u001b[1;34m(line)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_start_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;34m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\notebook.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(args_string)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mparsed_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshlex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[0mstart_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStartLaunched\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(arguments, timeout)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[0mend_time_seconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_time_seconds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend_time_seconds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoll_interval_seconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[0msubprocess_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msubprocess_result\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Para lanzarlo desde el jupyter notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "Para lanzarlo desde el terminal, hay que estar en la carpeta de los logs\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
